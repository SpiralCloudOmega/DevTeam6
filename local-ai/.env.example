# ======================================
# DevTeam6 Local AI Configuration
# ======================================

# Ollama LLM Service
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Embedding Model Configuration
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSIONS=768

# ChromaDB Vector Store
CHROMA_HOST=localhost
CHROMA_PORT=8001
CHROMA_PERSIST_DIR=./data/chroma
CHROMA_COLLECTION=devteam6

# OpenAI (Optional - for higher quality embeddings)
# OPENAI_API_KEY=sk-proj-your-key-here
# OPENAI_MODEL=gpt-4
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Anthropic (Optional - for Claude integration)
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# ANTHROPIC_MODEL=claude-3-opus-20240229

# API Server Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_CORS_ORIGINS=http://localhost:5173,http://localhost:5174,http://localhost:3000

# Context7 Multi-Agent System
CONTEXT7_SYNC_ENABLED=true
CONTEXT7_LOG_DIR=../.github/agents/logs
CONTEXT7_MEMORY_DIR=../.github/agents/memory

# Security Configuration
SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Performance Tuning
MAX_WORKERS=4
BATCH_SIZE=32
CACHE_TTL=3600

# Feature Flags
ENABLE_TELEMETRY=false
ENABLE_DEBUG_MODE=false
ENABLE_RATE_LIMITING=true

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=10

# Database Settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30

# Vector Store Settings
VECTOR_SIMILARITY_THRESHOLD=0.7
MAX_SEARCH_RESULTS=10
ENABLE_RERANKING=true

# MCP Server Settings
MCP_MEMORY_SERVER_ENABLED=true
MCP_RAG_SERVER_ENABLED=true
MCP_TOOL_TIMEOUT=30
